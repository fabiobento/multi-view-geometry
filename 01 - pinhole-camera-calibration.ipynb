{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Pinhole Camera Model Calibration\nThis notebook tells you how to calibrate your camera, finding its intrinsic parameters and distortion coefficients\n___\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## How to do it",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "1) Import the necessary modules        \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import cv2\nimport numpy as np",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "The `cv2.imshow()` and `cv.imshow()` functions from the `opencv-python` package are incompatible with Jupyter notebook ([see Stack Overflow issue \"cv2.imshow(img) is crashing the kernel\"](https://github.com/jupyter/notebook/issues/3935)).\nAs a replacement, you can use the following function:",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from google.colab.patches import cv2_imshow",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "2) Capture frames from the camera, detect a chessboard pattern on each frame, and accumulate the frames and corners until we have a big enough number of samples:\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "cap \u003d cv2.VideoCapture(0)\n\npattern_size \u003d (10, 7)\n\nsamples \u003d [ ]\n\nwhile True:\n    ret, frame \u003d cap.read()\n    if not ret:\n        break\n\n    res, corners \u003d cv2.findChessboardCorners(frame, pattern_size)\n\n    img_show \u003d np.copy(frame)\n    cv2.drawChessboardCorners(img_show, pattern_size, corners, res)\n    cv2.putText(img_show, \u0027Samples captured: %d\u0027 % len(samples), (0, 40),\n                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n    cv2_imshow(\u0027chessboard\u0027, img_show)\n\n    wait_time \u003d 0 if res else 30\n    k \u003d cv2.waitKey(wait_time)\n\n    if k \u003d\u003d ord(\u0027s\u0027) and res:\n        samples.append((cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), corners))\n    elif k \u003d\u003d 27:\n        break\n\ncap.release()\ncv2.destroyAllWindows()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "3) Refine all the detected corner points using `cv2.cornerSubPix`:",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "criteria \u003d (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3)\n\nfor i in range(len(samples)):\n    img, corners \u003d samples[i]\n    corners \u003d cv2.cornerSubPix(img, corners, (10, 10), (-1,-1), criteria)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "4) Find the camera\u0027s intrinsic parameters by passing all refined corner points to \u0027cv2.calibrateCamera\u0027:",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "pattern_points \u003d np.zeros((np.prod(pattern_size), 3), np.float32)\npattern_points[:, :2] \u003d np.indices(pattern_size).T.reshape(-1, 2)\n\nimages, corners \u003d zip(*samples)\n\npattern_points \u003d [pattern_points]*len(corners)\n\nrms, camera_matrix, dist_coefs, rvecs, tvecs \u003d \\\n    cv2.calibrateCamera(pattern_points, corners, images[0].shape, None, None)\n\nnp.save(\u0027camera_mat.npy\u0027, camera_matrix)\nnp.save(\u0027dist_coefs.npy\u0027, dist_coefs)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## How it works\nCamera calibration aims to find two sets of intrinsic parameters: the camera matrix and distortion coefficients (see [Camera Calibration and 3D Reconstruction](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html)). The camera matrix determines how coordinates of 3D points are mapped onto dimensionless pixels coordinates in the image, but actual image lenses also distort an image so straight lines are transformed into curves. Distortion coefficients allow you to eliminate such warps.\n\nThe whole camera calibration process can be divided into three stages:\n\n* Gathering a decent amount of data such as, images and detected chessboard patterns\n* Refining chessboard corners coordinates\n* Optimizing camera parameters to match them with observed distortions and projections\n\nTo gather data for camera calibration, you need to detect a chessboard pattern of a certain size and accumulate pairs of images and coordinates of the found corners. The function `cv2.findChessboardCorners` implements chessboard corner detection.\n\nIt\u0027s worth mentioning that corners on the chessboard are the ones formed by two black squares, and the pattern size you pass in `cv2.findChessboardCorners` should be the same as you have in the real chessboard pattern.\n\nThe number of samples and their distribution along the field of view is also very important. In practical cases, 50 to 100 samples is enough.\n\nThe next step is refining the corner\u0027s coordinates. This stage is necessary due to the fact that `cv2.findChessboardCorners` does not give a very accurate result, so we need to find the actual corner positions. `cv2.cornerSubPix` gives precision to corner coordinates with sub-pixel accuracy. It accepts the following arguments:\n* Grayscale images\n* Coarse coordinates of detected corners\n* Size of the refine region to find a more accurate corner position\n* Size of the zone in the center of the refine region to ignore\n* Criteria to stop the refining process\n\nCoarse coordinates of corners are the ones returned by `cv2.findChessboardCorners`. The refine region should be small, but it should include the actual position of the corner; otherwise, the coarse corner is returned. The size of the zone to ignore should be smaller than the refine region and can be disabled by passing (-1, -1) as its value. The stop criteria can be one of the following types, `cv2.TERM_CRITERIA_EPS` or `cv2.TERM_CRITERIA_MAX_ITER`, or a combinationof the two. `cv2.TERM_CRITERIA_EPS` determines the difference in previous and next corner positions. If the actual difference is less than the one defined, the process will be stopped. `cv2.TERM_CRITERIA_MAX_ITER` determines the maximum number of iterations. `cv2.cornerSubPix` returns the same number of corners with refined coordinates.\n\nOnce we have refined the corner\u0027s positions, it\u0027s time to find the camera\u0027s parameters. `cv2.calibrateCamera` solves this problem. You need to pass a few parameters to this function, and these are listed as follows:\n\n* Object points coordinates for all samples\n* Corners points coordinates for all samples\n* Shape of the images in (width, height) format\n* Two arrays to save translation and rotation vectors (can be set to None)\n* Flags and stop criteria (both have default values) \n\nObject points are 3D coordinates of chessboard corners in a chessboard coordinate system. Because we use the same pattern for each frame, the 3D coordinates of the corners are the same and, because we use equidistantly distributed corners, 3D coordinates are also equidistantly distributed on the plane (z\u003d0 for all points). The actual distance between corners doesn\u0027t matter because the camera eliminates the z coordinate (how far objects are from the camera), so it can be a smaller but closer pattern, or a bigger but farther oneâ€”the image is the same. `cv2.calibrateCamera` returns five values: the mean reprojection error for all samples, the camera matrix, distortion coefficients, rotation, and translation vectors for all samples. The reprojection error is the difference between a corner in the image and the projection of a 3D point of the corner. Ideally, the projection of the corner and its original position in the image should be the same, but there is a difference due to the noise. This difference is measured in pixels. The smaller this difference is, the better the calibration is done. The camera matrix has a shape of 3x3. The number of distortion coefficients depends on the flags and it equals 5 by default.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "pycharm-78b9c7c",
      "language": "python",
      "display_name": "PyCharm (multi-view-geometry)"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}