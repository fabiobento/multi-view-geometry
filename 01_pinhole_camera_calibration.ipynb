{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 - pinhole-camera-calibration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "pycharm-78b9c7c",
      "language": "python",
      "display_name": "PyCharm (multi-view-geometry)"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiobento/multi-view-geometry/blob/master/01_pinhole_camera_calibration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "id": "JeipO79Fsuit",
        "colab_type": "text"
      },
      "source": [
        "# Pinhole Camera Model Calibration\n",
        "This notebook tells you how to calibrate your camera, finding its intrinsic parameters and distortion coefficients\n",
        "___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "id": "Es7HxSz7suiv",
        "colab_type": "text"
      },
      "source": [
        "## How to do it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "id": "SUtWq9pasuiw",
        "colab_type": "text"
      },
      "source": [
        "1) Import the necessary modules        \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "HRt0C0Ifsuix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        },
        "id": "fr09OKdGsui1",
        "colab_type": "text"
      },
      "source": [
        "The `cv2.imshow()` and `cv.imshow()` functions from the `opencv-python` package are incompatible with Jupyter notebook ([see Stack Overflow issue \"cv2.imshow(img) is crashing the kernel\"](https://github.com/jupyter/notebook/issues/3935)).\n",
        "As a replacement, you can use the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "VXWwdU1qsui2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "id": "j7IhkTh3sui5",
        "colab_type": "text"
      },
      "source": [
        "2) Capture frames from the camera, detect a chessboard pattern on each frame, and accumulate the frames and corners until we have a big enough number of samples:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "QCPClcIasui5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "pattern_size = (10, 7)\n",
        "\n",
        "samples = [ ]\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    res, corners = cv2.findChessboardCorners(frame, pattern_size)\n",
        "\n",
        "    img_show = np.copy(frame)\n",
        "    cv2.drawChessboardCorners(img_show, pattern_size, corners, res)\n",
        "    cv2.putText(img_show, 'Samples captured: %d' % len(samples), (0, 40),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
        "    cv2_imshow('chessboard', img_show)\n",
        "\n",
        "    wait_time = 0 if res else 30\n",
        "    k = cv2.waitKey(wait_time)\n",
        "\n",
        "    if k == ord('s') and res:\n",
        "        samples.append((cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), corners))\n",
        "    elif k == 27:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        },
        "id": "GfYylVAJsui8",
        "colab_type": "text"
      },
      "source": [
        "3) Refine all the detected corner points using `cv2.cornerSubPix`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "p4aGtXR7sui9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3)\n",
        "\n",
        "for i in range(len(samples)):\n",
        "    img, corners = samples[i]\n",
        "    corners = cv2.cornerSubPix(img, corners, (10, 10), (-1,-1), criteria)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        },
        "id": "7Mcp1KiVsujA",
        "colab_type": "text"
      },
      "source": [
        "4) Find the camera's intrinsic parameters by passing all refined corner points to 'cv2.calibrateCamera':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "4hdqUHk4sujC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pattern_points = np.zeros((np.prod(pattern_size), 3), np.float32)\n",
        "pattern_points[:, :2] = np.indices(pattern_size).T.reshape(-1, 2)\n",
        "\n",
        "images, corners = zip(*samples)\n",
        "\n",
        "pattern_points = [pattern_points]*len(corners)\n",
        "\n",
        "rms, camera_matrix, dist_coefs, rvecs, tvecs = \\\n",
        "    cv2.calibrateCamera(pattern_points, corners, images[0].shape, None, None)\n",
        "\n",
        "np.save('camera_mat.npy', camera_matrix)\n",
        "np.save('dist_coefs.npy', dist_coefs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        },
        "id": "WCwfyisJsujF",
        "colab_type": "text"
      },
      "source": [
        "## How it works\n",
        "Camera calibration aims to find two sets of intrinsic parameters: the camera matrix and distortion coefficients (see [Camera Calibration and 3D Reconstruction](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html)). The camera matrix determines how coordinates of 3D points are mapped onto dimensionless pixels coordinates in the image, but actual image lenses also distort an image so straight lines are transformed into curves. Distortion coefficients allow you to eliminate such warps.\n",
        "\n",
        "The whole camera calibration process can be divided into three stages:\n",
        "\n",
        "* Gathering a decent amount of data such as, images and detected chessboard patterns\n",
        "* Refining chessboard corners coordinates\n",
        "* Optimizing camera parameters to match them with observed distortions and projections\n",
        "\n",
        "To gather data for camera calibration, you need to detect a chessboard pattern of a certain size and accumulate pairs of images and coordinates of the found corners. The function `cv2.findChessboardCorners` implements chessboard corner detection.\n",
        "\n",
        "It's worth mentioning that corners on the chessboard are the ones formed by two black squares, and the pattern size you pass in `cv2.findChessboardCorners` should be the same as you have in the real chessboard pattern.\n",
        "\n",
        "The number of samples and their distribution along the field of view is also very important. In practical cases, 50 to 100 samples is enough.\n",
        "\n",
        "The next step is refining the corner's coordinates. This stage is necessary due to the fact that `cv2.findChessboardCorners` does not give a very accurate result, so we need to find the actual corner positions. `cv2.cornerSubPix` gives precision to corner coordinates with sub-pixel accuracy. It accepts the following arguments:\n",
        "* Grayscale images\n",
        "* Coarse coordinates of detected corners\n",
        "* Size of the refine region to find a more accurate corner position\n",
        "* Size of the zone in the center of the refine region to ignore\n",
        "* Criteria to stop the refining process\n",
        "\n",
        "Coarse coordinates of corners are the ones returned by `cv2.findChessboardCorners`. The refine region should be small, but it should include the actual position of the corner; otherwise, the coarse corner is returned. The size of the zone to ignore should be smaller than the refine region and can be disabled by passing (-1, -1) as its value. The stop criteria can be one of the following types, `cv2.TERM_CRITERIA_EPS` or `cv2.TERM_CRITERIA_MAX_ITER`, or a combinationof the two. `cv2.TERM_CRITERIA_EPS` determines the difference in previous and next corner positions. If the actual difference is less than the one defined, the process will be stopped. `cv2.TERM_CRITERIA_MAX_ITER` determines the maximum number of iterations. `cv2.cornerSubPix` returns the same number of corners with refined coordinates.\n",
        "\n",
        "Once we have refined the corner's positions, it's time to find the camera's parameters. `cv2.calibrateCamera` solves this problem. You need to pass a few parameters to this function, and these are listed as follows:\n",
        "\n",
        "* Object points coordinates for all samples\n",
        "* Corners points coordinates for all samples\n",
        "* Shape of the images in (width, height) format\n",
        "* Two arrays to save translation and rotation vectors (can be set to None)\n",
        "* Flags and stop criteria (both have default values) \n",
        "\n",
        "Object points are 3D coordinates of chessboard corners in a chessboard coordinate system. Because we use the same pattern for each frame, the 3D coordinates of the corners are the same and, because we use equidistantly distributed corners, 3D coordinates are also equidistantly distributed on the plane (z=0 for all points). The actual distance between corners doesn't matter because the camera eliminates the z coordinate (how far objects are from the camera), so it can be a smaller but closer pattern, or a bigger but farther one—the image is the same. `cv2.calibrateCamera` returns five values: the mean reprojection error for all samples, the camera matrix, distortion coefficients, rotation, and translation vectors for all samples. The reprojection error is the difference between a corner in the image and the projection of a 3D point of the corner. Ideally, the projection of the corner and its original position in the image should be the same, but there is a difference due to the noise. This difference is measured in pixels. The smaller this difference is, the better the calibration is done. The camera matrix has a shape of 3x3. The number of distortion coefficients depends on the flags and it equals 5 by default."
      ]
    }
  ]
}